{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/notebook/kaggle/'\n",
    "PROJ_HOME_DIR = path + 'data/ultrasound/'\n",
    "DATA_HOME_DIR = PROJ_HOME_DIR # + 'sample/'\n",
    "\n",
    "results_path = DATA_HOME_DIR + 'results/'\n",
    "test_path = DATA_HOME_DIR + 'test/'\n",
    "valid_path = DATA_HOME_DIR + 'valid/'\n",
    "train_path = DATA_HOME_DIR + 'train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already satisfied: six>=1.7.3 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: functools32 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: subprocess32 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from pillow>=2.1.0->scikit-image)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python2.7/dist-packages (from networkx>=1.8->scikit-image)\n",
      "Collecting kaggle-cli\n",
      "  Downloading kaggle-cli-0.12.10.tar.gz\n",
      "Collecting cliff<2.9,>=2.8.0 (from kaggle-cli)\n",
      "  Downloading cliff-2.8.0-py2-none-any.whl (68kB)\n",
      "\u001b[K    100% |################################| 71kB 1.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting MechanicalSoup<0.9,>=0.7.0 (from kaggle-cli)\n",
      "  Downloading MechanicalSoup-0.8.0-py2.py3-none-any.whl\n",
      "Collecting lxml<4.1,>=4.0.0 (from kaggle-cli)\n",
      "  Downloading lxml-4.0.0-cp27-cp27mu-manylinux1_x86_64.whl (5.3MB)\n",
      "\u001b[K    100% |################################| 5.3MB 249kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cssselect<1.1,>=1.0.1 (from kaggle-cli)\n",
      "  Downloading cssselect-1.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: configparser in /usr/local/lib/python2.7/dist-packages (from kaggle-cli)\n",
      "Collecting progressbar2<3.35,>=3.34.3 (from kaggle-cli)\n",
      "  Downloading progressbar2-3.34.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: PyYAML>=3.10.0 in /usr/local/lib/python2.7/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python2.7/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "Collecting unicodecsv>=0.8.0; python_version < \"3.0\" (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "  Downloading unicodecsv-0.14.1.tar.gz\n",
      "Collecting PrettyTable<0.8,>=0.7.1 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "  Downloading prettytable-0.7.2.zip\n",
      "Collecting cmd2>=0.6.7 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "  Downloading cmd2-0.7.7.tar.gz (69kB)\n",
      "\u001b[K    100% |################################| 71kB 5.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting stevedore>=1.20.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "  Downloading stevedore-1.27.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "Collecting beautifulsoup4 (from MechanicalSoup<0.9,>=0.7.0->kaggle-cli)\n",
      "  Downloading beautifulsoup4-4.6.0-py2-none-any.whl (86kB)\n",
      "\u001b[K    100% |################################| 92kB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.0 in /usr/local/lib/python2.7/dist-packages (from MechanicalSoup<0.9,>=0.7.0->kaggle-cli)\n",
      "Collecting python-utils>=2.1.0 (from progressbar2<3.35,>=3.34.3->kaggle-cli)\n",
      "  Downloading python_utils-2.2.0-py2.py3-none-any.whl\n",
      "Collecting pyperclip (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
      "  Downloading pyperclip-1.5.32.tar.gz\n",
      "Building wheels for collected packages: kaggle-cli, unicodecsv, PrettyTable, cmd2, pyperclip\n",
      "  Running setup.py bdist_wheel for kaggle-cli ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/16/28/c7/78658216416b7b481df91b485e43b6722daf59e71fc9cf9a58\n",
      "  Running setup.py bdist_wheel for unicodecsv ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/e2/16/219fa93b83edaff912b6805cfa19d0597e21f8d353f3e2d22f\n",
      "  Running setup.py bdist_wheel for PrettyTable ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b6/90/7b/1c22b89217d0eba6d5f406e562365ebee804f0d4595b2bdbcd\n",
      "  Running setup.py bdist_wheel for cmd2 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/aa/51/63/dfeef1471ea77d2e622021366ff563e07d5e95a502eb3eb19a\n",
      "  Running setup.py bdist_wheel for pyperclip ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/dd/9b/cf/eb3bda3924e3c3f21f627da365f146354563d529cc77df7be9\n",
      "Successfully built kaggle-cli unicodecsv PrettyTable cmd2 pyperclip\n",
      "Installing collected packages: unicodecsv, PrettyTable, pyperclip, cmd2, stevedore, cliff, beautifulsoup4, MechanicalSoup, lxml, cssselect, python-utils, progressbar2, kaggle-cli\n",
      "  Found existing installation: lxml 3.7.3\n",
      "    Uninstalling lxml-3.7.3:\n",
      "      Successfully uninstalled lxml-3.7.3\n",
      "Successfully installed MechanicalSoup-0.8.0 PrettyTable-0.7.2 beautifulsoup4-4.6.0 cliff-2.8.0 cmd2-0.7.7 cssselect-1.0.1 kaggle-cli-0.12.10 lxml-4.0.0 progressbar2-3.34.3 pyperclip-1.5.32 python-utils-2.2.0 stevedore-1.27.1 unicodecsv-0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image\n",
    "!pip install kaggle-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(path+'kaggle.txt') as json_file:  \n",
    "    kg_data = json.load(json_file)\n",
    "    \n",
    "username = kg_data['username']\n",
    "password = kg_data['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%cd $DATA_HOME_DIR\\n!kg download\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!kg config -g -u $username -p $password -c 'ultrasound-nerve-segmentation'\n",
    "\n",
    "'''\n",
    "%cd $DATA_HOME_DIR\n",
    "!kg download\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "#import sys\n",
    "#sys.path.append('/notebook/kaggle/data/ultrasound')\n",
    "#from data import load_train_data, load_test_data\n",
    "\n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    "\n",
    "img_rows = 96\n",
    "img_cols = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    ''' Convert images to np arrays of 8-bit unsigned integers and standardize shape '''\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This competition is evaluated on the mean [Dice coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient). The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dice coefficient between actual and predicted pixels\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "\n",
    "# Loss of Dice coefficient between actual and predicted pixels\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create and compile [**u-net model**](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/): a network that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization.\n",
    "[More info...](https://arxiv.org/abs/1505.04597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((img_rows, img_cols, 1))\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "model_checkpoint = ModelCheckpoint(results_path+'weights.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess train data\n",
    "imgs_train = preprocess(np.load(DATA_HOME_DIR+'imgs_train.npy'))\n",
    "imgs_mask_train = preprocess(np.load(DATA_HOME_DIR+'imgs_mask_train.npy'))\n",
    "\n",
    "# Normalize data\n",
    "imgs_train = imgs_train.astype('float32')\n",
    "mean = np.mean(imgs_train)  # Mean for data centering\n",
    "std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "imgs_train -= mean\n",
    "imgs_train /= std\n",
    "\n",
    "imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "imgs_mask_train /= 255.  # scale masks to [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/20\n",
      "4508/4508 [==============================] - 20s - loss: -0.0247 - dice_coef: 0.0247 - val_loss: -0.0242 - val_dice_coef: 0.0242\n",
      "Epoch 2/20\n",
      "4508/4508 [==============================] - 17s - loss: -0.0981 - dice_coef: 0.0981 - val_loss: -0.2171 - val_dice_coef: 0.2171\n",
      "Epoch 3/20\n",
      "4508/4508 [==============================] - 17s - loss: -0.2261 - dice_coef: 0.2261 - val_loss: -0.2427 - val_dice_coef: 0.2427\n",
      "Epoch 4/20\n",
      "4508/4508 [==============================] - 17s - loss: -0.2533 - dice_coef: 0.2533 - val_loss: -0.2095 - val_dice_coef: 0.2095\n",
      "Epoch 5/20\n",
      "4508/4508 [==============================] - 18s - loss: -0.2699 - dice_coef: 0.2699 - val_loss: -0.2634 - val_dice_coef: 0.2634\n",
      "Epoch 6/20\n",
      "4508/4508 [==============================] - 18s - loss: -0.2942 - dice_coef: 0.2942 - val_loss: -0.3012 - val_dice_coef: 0.3012\n",
      "Epoch 7/20\n",
      "4508/4508 [==============================] - 17s - loss: -0.3178 - dice_coef: 0.3178 - val_loss: -0.2893 - val_dice_coef: 0.2893\n",
      "Epoch 8/20\n",
      "4508/4508 [==============================] - 18s - loss: -0.3306 - dice_coef: 0.3306 - val_loss: -0.3518 - val_dice_coef: 0.3518\n",
      "Epoch 9/20\n",
      "4508/4508 [==============================] - 18s - loss: -0.3635 - dice_coef: 0.3635 - val_loss: -0.3784 - val_dice_coef: 0.3784\n",
      "Epoch 10/20\n",
      "4508/4508 [==============================] - 18s - loss: -0.3906 - dice_coef: 0.3906 - val_loss: -0.3984 - val_dice_coef: 0.3984\n",
      "Epoch 11/20\n",
      "4508/4508 [==============================] - 18s - loss: -0.4189 - dice_coef: 0.4189 - val_loss: -0.4220 - val_dice_coef: 0.4220\n",
      "Epoch 12/20\n",
      "4508/4508 [==============================] - 18s - loss: -0.4404 - dice_coef: 0.4404 - val_loss: -0.4429 - val_dice_coef: 0.4429\n",
      "Epoch 13/20\n",
      "4508/4508 [==============================] - 18s - loss: -0.4598 - dice_coef: 0.4598 - val_loss: -0.4631 - val_dice_coef: 0.4631\n",
      "Epoch 14/20\n",
      "4480/4508 [============================>.] - ETA: 0s - loss: -0.4737 - dice_coef: 0.4737"
     ]
    }
   ],
   "source": [
    "model.fit(imgs_train, imgs_mask_train, batch_size=32, epochs=20, verbose=1, shuffle=True,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and preprocess test data\n",
    "imgs_test = preprocess(np.load(DATA_HOME_DIR+'imgs_test.npy'))\n",
    "imgs_id_test = np.load(DATA_HOME_DIR+'imgs_id_test.npy')\n",
    "\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "imgs_test -= mean\n",
    "imgs_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved weights\n",
    "model.load_weights(results_path+'weights.h5')\n",
    "\n",
    "# Predict masks using test data\n",
    "imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "np.save('imgs_mask_test.npy', imgs_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted masks to file\n",
    "pred_dir = results_path+'preds'\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.mkdir(pred_dir)\n",
    "for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "    image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "    imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "\n",
    "#import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "image_rows = 420\n",
    "image_cols = 580\n",
    "\n",
    "def prep(img):\n",
    "    img = img.astype('float32')\n",
    "    img = (img > 0.5).astype(np.uint8)  # threshold\n",
    "    img = resize(img, (image_cols, image_rows), preserve_range=True)\n",
    "    return img\n",
    "\n",
    "def run_length_enc(label):\n",
    "    from itertools import chain\n",
    "    x = label.transpose().flatten()\n",
    "    y = np.where(x > 0)[0]\n",
    "    if len(y) < 10:  # consider as empty\n",
    "        return ''\n",
    "    z = np.where(np.diff(y) > 1)[0]\n",
    "    start = np.insert(y[z+1], 0, y[0])\n",
    "    end = np.append(y[z], y[-1])\n",
    "    length = end - start\n",
    "    res = [[s+1, l+1] for s, l in zip(list(start), list(length))]\n",
    "    res = list(chain.from_iterable(res))\n",
    "    return ' '.join([str(r) for r in res])\n",
    "\n",
    "# Create .csv for submission\n",
    "argsort = np.argsort(imgs_id_test)\n",
    "imgs_id_test = imgs_id_test[argsort]\n",
    "imgs_test = imgs_test[argsort]\n",
    "\n",
    "total = imgs_test.shape[0]\n",
    "ids = []\n",
    "rles = []\n",
    "for i in range(total):\n",
    "    img = imgs_test[i, 0]\n",
    "    img = prep(img)\n",
    "    rle = run_length_enc(img)\n",
    "\n",
    "    rles.append(rle)\n",
    "    ids.append(imgs_id_test[i])\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print('{}/{}'.format(i, total))\n",
    "\n",
    "first_row = 'img,pixels'\n",
    "file_name = results_path+'submission.csv'\n",
    "\n",
    "with open(file_name, 'w+') as f:\n",
    "    f.write(first_row + '\\n')\n",
    "    for i in range(total):\n",
    "        s = str(ids[i]) + ',' + rles[i]\n",
    "        f.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = results_path+'submission.csv'\n",
    "! kg submit $file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
